{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3445c9855ff311e7",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - Labelled Financial News Data Using Transformer Models\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7fe6ac1d1f0f6129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:14.683709Z",
     "start_time": "2024-05-18T13:59:14.679750Z"
    }
   },
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "b93ec5afcbb2d02a",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "aa625c70a8cfa0b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:14.951888Z",
     "start_time": "2024-05-18T13:59:14.930136Z"
    }
   },
   "source": [
    "data = pd.read_csv('data/Fin_cleaned.csv', encoding='utf-8')\n",
    "\n",
    "# duplicate the data\n",
    "news = data.copy()\n",
    "\n",
    "news"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Date_published                                           Headline  \\\n",
       "0       2022-06-21  Banks holding on to subsidy share, say payment...   \n",
       "1       2022-04-19  Digitally ready Bank of Baroda aims to click o...   \n",
       "2       2022-05-27  Karnataka attracted investment commitment of R...   \n",
       "3       2022-04-06  Splitting of provident fund accounts may be de...   \n",
       "4       2022-06-14  Irdai weighs proposal to privatise Insurance I...   \n",
       "..             ...                                                ...   \n",
       "395     2022-06-10      Banks take a cue from RBI, hike lending rates   \n",
       "396     2022-06-29  Sebi issues Rs 27 lakh recovery notice to indi...   \n",
       "397     2022-06-06  Apollo Hospital shares  drop  0.68% as Sensex ...   \n",
       "398     2022-05-16  SBI at Rs 710? What makes analysts see up to 5...   \n",
       "399     2022-05-27  Stock market update: Mining stocks  up  as mar...   \n",
       "\n",
       "                                              Synopsis  \\\n",
       "0    The companies have written to the National Pay...   \n",
       "1    At present, 50% of the bank's retail loans are...   \n",
       "2    Karnataka is at the forefront in attracting in...   \n",
       "3    The EPFO is likely to split accounts only at t...   \n",
       "4    Set up in 2009 as an advisory body, IIB collec...   \n",
       "..                                                 ...   \n",
       "395  These banks raised their respective external b...   \n",
       "396  In the event of non-payment, it will recover t...   \n",
       "397  A total of 10,105 shares changed hands on the ...   \n",
       "398  Calling the stock 'attractively valued' analys...   \n",
       "399  The 30-share BSE Sensex was  up  323.71 points...   \n",
       "\n",
       "                                             Full_text Final Status  \n",
       "0    ReutersPayments companies and banks are at log...     Negative  \n",
       "1    AgenciesThe bank presently has 20 million acti...     Positive  \n",
       "2    PTIKarnataka Chief Minister Basavaraj Bommai.K...     Positive  \n",
       "3    Getty ImagesThe budget for FY22 had imposed in...     Negative  \n",
       "4    AgenciesThere is a view in the insurance indus...     Positive  \n",
       "..                                                 ...          ...  \n",
       "395  PTIICICI Bank, Bank of Baroda, Punjab National...     Negative  \n",
       "396  ReutersThe logo of the Securities and Exchange...     Negative  \n",
       "397  Getty ImagesShrikant Chouhan of Kotak Securiti...     Negative  \n",
       "398  AgenciesThe PSU bank reported a 41.27 per cent...     Positive  \n",
       "399  Shutterstock.comAgarwal said the global econom...     Positive  \n",
       "\n",
       "[400 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_published</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Synopsis</th>\n",
       "      <th>Full_text</th>\n",
       "      <th>Final Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Banks holding on to subsidy share, say payment...</td>\n",
       "      <td>The companies have written to the National Pay...</td>\n",
       "      <td>ReutersPayments companies and banks are at log...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>Digitally ready Bank of Baroda aims to click o...</td>\n",
       "      <td>At present, 50% of the bank's retail loans are...</td>\n",
       "      <td>AgenciesThe bank presently has 20 million acti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>Karnataka attracted investment commitment of R...</td>\n",
       "      <td>Karnataka is at the forefront in attracting in...</td>\n",
       "      <td>PTIKarnataka Chief Minister Basavaraj Bommai.K...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Splitting of provident fund accounts may be de...</td>\n",
       "      <td>The EPFO is likely to split accounts only at t...</td>\n",
       "      <td>Getty ImagesThe budget for FY22 had imposed in...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>Irdai weighs proposal to privatise Insurance I...</td>\n",
       "      <td>Set up in 2009 as an advisory body, IIB collec...</td>\n",
       "      <td>AgenciesThere is a view in the insurance indus...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>Banks take a cue from RBI, hike lending rates</td>\n",
       "      <td>These banks raised their respective external b...</td>\n",
       "      <td>PTIICICI Bank, Bank of Baroda, Punjab National...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>Sebi issues Rs 27 lakh recovery notice to indi...</td>\n",
       "      <td>In the event of non-payment, it will recover t...</td>\n",
       "      <td>ReutersThe logo of the Securities and Exchange...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>Apollo Hospital shares  drop  0.68% as Sensex ...</td>\n",
       "      <td>A total of 10,105 shares changed hands on the ...</td>\n",
       "      <td>Getty ImagesShrikant Chouhan of Kotak Securiti...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>SBI at Rs 710? What makes analysts see up to 5...</td>\n",
       "      <td>Calling the stock 'attractively valued' analys...</td>\n",
       "      <td>AgenciesThe PSU bank reported a 41.27 per cent...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>Stock market update: Mining stocks  up  as mar...</td>\n",
       "      <td>The 30-share BSE Sensex was  up  323.71 points...</td>\n",
       "      <td>Shutterstock.comAgarwal said the global econom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "d5cb83a1a8d98f7a",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "a5d6d1dadbee521b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:14.983111Z",
     "start_time": "2024-05-18T13:59:14.958893Z"
    }
   },
   "source": [
    "# Fill the missing value with an empty string\n",
    "news['Synopsis'] = news['Synopsis'].fillna('')\n",
    "\n",
    "# Rename columns\n",
    "news = news.rename(\n",
    "    columns={'Date_published': 'date', 'Headline': 'headline', 'Synopsis': 'synopsis', 'Full_text': 'text',\n",
    "             'Final Status': 'label'})\n",
    "\n",
    "# Remove the spaces from the labels\n",
    "news['label'] = news['label'].str.strip()\n",
    "\n",
    "# Combine the headline, synopsis, and text columns\n",
    "news['full_text'] = news['headline'] + ' ' + news['synopsis'] + ' ' + news['text']\n",
    "\n",
    "# Convert labels to binary\n",
    "news['label'] = news['label'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "news"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date                                           headline  \\\n",
       "0    2022-06-21  Banks holding on to subsidy share, say payment...   \n",
       "1    2022-04-19  Digitally ready Bank of Baroda aims to click o...   \n",
       "2    2022-05-27  Karnataka attracted investment commitment of R...   \n",
       "3    2022-04-06  Splitting of provident fund accounts may be de...   \n",
       "4    2022-06-14  Irdai weighs proposal to privatise Insurance I...   \n",
       "..          ...                                                ...   \n",
       "395  2022-06-10      Banks take a cue from RBI, hike lending rates   \n",
       "396  2022-06-29  Sebi issues Rs 27 lakh recovery notice to indi...   \n",
       "397  2022-06-06  Apollo Hospital shares  drop  0.68% as Sensex ...   \n",
       "398  2022-05-16  SBI at Rs 710? What makes analysts see up to 5...   \n",
       "399  2022-05-27  Stock market update: Mining stocks  up  as mar...   \n",
       "\n",
       "                                              synopsis  \\\n",
       "0    The companies have written to the National Pay...   \n",
       "1    At present, 50% of the bank's retail loans are...   \n",
       "2    Karnataka is at the forefront in attracting in...   \n",
       "3    The EPFO is likely to split accounts only at t...   \n",
       "4    Set up in 2009 as an advisory body, IIB collec...   \n",
       "..                                                 ...   \n",
       "395  These banks raised their respective external b...   \n",
       "396  In the event of non-payment, it will recover t...   \n",
       "397  A total of 10,105 shares changed hands on the ...   \n",
       "398  Calling the stock 'attractively valued' analys...   \n",
       "399  The 30-share BSE Sensex was  up  323.71 points...   \n",
       "\n",
       "                                                  text  label  \\\n",
       "0    ReutersPayments companies and banks are at log...      0   \n",
       "1    AgenciesThe bank presently has 20 million acti...      1   \n",
       "2    PTIKarnataka Chief Minister Basavaraj Bommai.K...      1   \n",
       "3    Getty ImagesThe budget for FY22 had imposed in...      0   \n",
       "4    AgenciesThere is a view in the insurance indus...      1   \n",
       "..                                                 ...    ...   \n",
       "395  PTIICICI Bank, Bank of Baroda, Punjab National...      0   \n",
       "396  ReutersThe logo of the Securities and Exchange...      0   \n",
       "397  Getty ImagesShrikant Chouhan of Kotak Securiti...      0   \n",
       "398  AgenciesThe PSU bank reported a 41.27 per cent...      1   \n",
       "399  Shutterstock.comAgarwal said the global econom...      1   \n",
       "\n",
       "                                             full_text  \n",
       "0    Banks holding on to subsidy share, say payment...  \n",
       "1    Digitally ready Bank of Baroda aims to click o...  \n",
       "2    Karnataka attracted investment commitment of R...  \n",
       "3    Splitting of provident fund accounts may be de...  \n",
       "4    Irdai weighs proposal to privatise Insurance I...  \n",
       "..                                                 ...  \n",
       "395  Banks take a cue from RBI, hike lending rates ...  \n",
       "396  Sebi issues Rs 27 lakh recovery notice to indi...  \n",
       "397  Apollo Hospital shares  drop  0.68% as Sensex ...  \n",
       "398  SBI at Rs 710? What makes analysts see up to 5...  \n",
       "399  Stock market update: Mining stocks  up  as mar...  \n",
       "\n",
       "[400 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-21</td>\n",
       "      <td>Banks holding on to subsidy share, say payment...</td>\n",
       "      <td>The companies have written to the National Pay...</td>\n",
       "      <td>ReutersPayments companies and banks are at log...</td>\n",
       "      <td>0</td>\n",
       "      <td>Banks holding on to subsidy share, say payment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-19</td>\n",
       "      <td>Digitally ready Bank of Baroda aims to click o...</td>\n",
       "      <td>At present, 50% of the bank's retail loans are...</td>\n",
       "      <td>AgenciesThe bank presently has 20 million acti...</td>\n",
       "      <td>1</td>\n",
       "      <td>Digitally ready Bank of Baroda aims to click o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>Karnataka attracted investment commitment of R...</td>\n",
       "      <td>Karnataka is at the forefront in attracting in...</td>\n",
       "      <td>PTIKarnataka Chief Minister Basavaraj Bommai.K...</td>\n",
       "      <td>1</td>\n",
       "      <td>Karnataka attracted investment commitment of R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Splitting of provident fund accounts may be de...</td>\n",
       "      <td>The EPFO is likely to split accounts only at t...</td>\n",
       "      <td>Getty ImagesThe budget for FY22 had imposed in...</td>\n",
       "      <td>0</td>\n",
       "      <td>Splitting of provident fund accounts may be de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>Irdai weighs proposal to privatise Insurance I...</td>\n",
       "      <td>Set up in 2009 as an advisory body, IIB collec...</td>\n",
       "      <td>AgenciesThere is a view in the insurance indus...</td>\n",
       "      <td>1</td>\n",
       "      <td>Irdai weighs proposal to privatise Insurance I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2022-06-10</td>\n",
       "      <td>Banks take a cue from RBI, hike lending rates</td>\n",
       "      <td>These banks raised their respective external b...</td>\n",
       "      <td>PTIICICI Bank, Bank of Baroda, Punjab National...</td>\n",
       "      <td>0</td>\n",
       "      <td>Banks take a cue from RBI, hike lending rates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2022-06-29</td>\n",
       "      <td>Sebi issues Rs 27 lakh recovery notice to indi...</td>\n",
       "      <td>In the event of non-payment, it will recover t...</td>\n",
       "      <td>ReutersThe logo of the Securities and Exchange...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sebi issues Rs 27 lakh recovery notice to indi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>Apollo Hospital shares  drop  0.68% as Sensex ...</td>\n",
       "      <td>A total of 10,105 shares changed hands on the ...</td>\n",
       "      <td>Getty ImagesShrikant Chouhan of Kotak Securiti...</td>\n",
       "      <td>0</td>\n",
       "      <td>Apollo Hospital shares  drop  0.68% as Sensex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>SBI at Rs 710? What makes analysts see up to 5...</td>\n",
       "      <td>Calling the stock 'attractively valued' analys...</td>\n",
       "      <td>AgenciesThe PSU bank reported a 41.27 per cent...</td>\n",
       "      <td>1</td>\n",
       "      <td>SBI at Rs 710? What makes analysts see up to 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>Stock market update: Mining stocks  up  as mar...</td>\n",
       "      <td>The 30-share BSE Sensex was  up  323.71 points...</td>\n",
       "      <td>Shutterstock.comAgarwal said the global econom...</td>\n",
       "      <td>1</td>\n",
       "      <td>Stock market update: Mining stocks  up  as mar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a dataset dictionary",
   "id": "41318a80f738bc14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:15.011210Z",
     "start_time": "2024-05-18T13:59:14.988354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dataset dictionary\n",
    "dataset = Dataset.from_pandas(news[[\"full_text\", 'label']])\n",
    "\n",
    "# Display the dataset dictionary    \n",
    "dataset"
   ],
   "id": "f1fff9f65bd23923",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['full_text', 'label'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "1bf44a3c66ec506d",
   "metadata": {},
   "source": "## Split the dataset into training and testing sets"
  },
  {
   "cell_type": "code",
   "id": "d52ffcdfbb353e31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:15.080802Z",
     "start_time": "2024-05-18T13:59:15.069257Z"
    }
   },
   "source": [
    "# We will split the dataset into 80% training and 20% testing\n",
    "train_test = dataset.train_test_split(test_size=0.2, seed=42)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "2fa832572163e894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:15.110825Z",
     "start_time": "2024-05-18T13:59:15.103154Z"
    }
   },
   "source": [
    "# Now we will split the test set into 50% validation and 50% test\n",
    "valid_test = train_test['test'].train_test_split(test_size=0.5, seed=42)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create a final dataset dictionary",
   "id": "fd370551a0f7a174"
  },
  {
   "cell_type": "code",
   "id": "7a69fdc07ed9c9b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:15.240042Z",
     "start_time": "2024-05-18T13:59:15.235269Z"
    }
   },
   "source": [
    "# Combine the training, validation, and testing sets into a single dictionary\n",
    "final_dataset = DatasetDict({\n",
    "    'train': train_test['train'],\n",
    "    'validation': valid_test['train'],\n",
    "    'test': valid_test['test']\n",
    "})\n",
    "\n",
    "final_dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_text', 'label'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['full_text', 'label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_text', 'label'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Defining models",
   "id": "87f2c09209b67c36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:16.441393Z",
     "start_time": "2024-05-18T13:59:15.321008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Models names\n",
    "model_names = [\n",
    "    \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\",\n",
    "    \"distilbert-base-uncased\",\n",
    "    \"ProsusAI/finbert\"\n",
    "]\n",
    "\n",
    "# Hugging Face organization name for the models saving\n",
    "huggingface_owner = \"rnribeiro/\"\n",
    "\n",
    "# Create a models dictionary\n",
    "models = {\n",
    "    model: {\n",
    "        'ft_saving_dir': huggingface_owner + \"FT-\" + model.replace(\"/\", \"-\"),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained(model),\n",
    "        'ft_dataset': DatasetDict({\n",
    "            'train': train_test['train'],\n",
    "            'validation': valid_test['train'],\n",
    "            'test': valid_test['test']\n",
    "        }),  # Dataset for Fine-tuning\n",
    "    }\n",
    "    for model in model_names\n",
    "}\n"
   ],
   "id": "6f37417161dce39d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization of the dataset",
   "id": "8028f5cdd8eb41e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:18.037799Z",
     "start_time": "2024-05-18T13:59:16.443432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to tokenize the dataset\n",
    "def ft_tokenize_function(model, examples):\n",
    "    return model['tokenizer'](examples['full_text'], truncation=True, padding='max_length')\n",
    "\n",
    "# Tokenize the dataset\n",
    "for model in model_names:\n",
    "    models[model]['ft_dataset'] = models[model]['ft_dataset'].map(\n",
    "        lambda examples: ft_tokenize_function(models[model], examples),\n",
    "        batched=True)\n",
    "\n",
    "models[model_names[0]]['ft_dataset']"
   ],
   "id": "ee371373db9a236c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfb69d9e7517405ba2038c354ef0cb0f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efe599ee59d14253a8afbf0e68f42cb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19a7d99f6a034a09a88fd2f880de6710"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a771227df8f49d1b3e1cef14a86e6f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3164a02dc254aa6b5bb4aea04e4b191"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd28b6bb618142bd9cd5dd840614dc59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2e946e0a9bb445384217b6a97ca913c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4c4c742fd17421286ddef63584a8c34"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "923fdd52ec3f42999785316e6ad88ddf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['full_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 40\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "7944232b173f18f7",
   "metadata": {},
   "source": "## Loading models"
  },
  {
   "cell_type": "markdown",
   "id": "869b1164b2d66cb2",
   "metadata": {},
   "source": [
    "This model is a distilled version of the RoBERTa-base model. It follows the same training procedure as DistilBERT.\n",
    "The model has 6 layers, 768 dimension and 12 heads, totalizing 82M parameters (compared to 125M parameters for RoBERTa-base). On average DistilRoBERTa is twice as fast as Roberta-base."
   ]
  },
  {
   "cell_type": "code",
   "id": "d24baee96a243fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T13:59:22.288995Z",
     "start_time": "2024-05-18T13:59:18.037799Z"
    }
   },
   "source": [
    "# Load the metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "# Define the function to compute the metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "# Load all models\n",
    "for model in model_names:\n",
    "    # Load the model for fine-tuning\n",
    "    models[model]['ft_model'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model, num_labels=2, ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # Define the training arguments\n",
    "    models[model]['ft_training_args'] = TrainingArguments(\n",
    "        output_dir=\"./ft_training_results/\" + model.replace(\"/\", \"-\"),\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=True,\n",
    "        hub_model_id=models[model]['ft_saving_dir'],\n",
    "    )\n",
    "\n",
    "    # Define the data collator\n",
    "    models[model]['ft_data_collator'] = DataCollatorWithPadding(tokenizer=models[model]['tokenizer'])\n",
    "\n",
    "    # Define the trainer\n",
    "    models[model]['ft_trainer'] = Trainer(\n",
    "        model=models[model]['ft_model'],\n",
    "        args=models[model]['ft_training_args'],\n",
    "        train_dataset=models[model]['ft_dataset']['train'],\n",
    "        eval_dataset=models[model]['ft_dataset']['validation'],\n",
    "        data_collator=models[model]['ft_data_collator'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=models[model]['tokenizer']\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\rnrib\\miniconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ProsusAI/finbert and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "c0f87b79edc8c83e",
   "metadata": {},
   "source": "## Fine-tuning the models"
  },
  {
   "cell_type": "code",
   "id": "f907b9f3980215c0",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-18T13:59:22.291005Z"
    }
   },
   "source": [
    "# Train the model\n",
    "ft_train = True\n",
    "if ft_train:\n",
    "    for model in model_names:\n",
    "        print(f\"Training {model}...\")\n",
    "        models[model]['ft_trainer'].train()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/120 00:09 < 08:57, 0.22 it/s, Epoch 0.07/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd1e9f3b8b910063",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Evaluate the model\n",
    "if ft_train:\n",
    "    for model in model_names:\n",
    "        print(f\"Evaluating {model}...\")\n",
    "        models[model]['ft_trainer'].evaluate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model to the hub\n",
    "if ft_train:\n",
    "    for model in model_names:\n",
    "        print(f\"Pushing {model} to Hugging Face...\")\n",
    "        models[model]['ft_trainer'].push_to_hub()"
   ],
   "id": "7495d10ea661f5c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading trained models",
   "id": "ce7bee7a399148d0"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_names:\n",
    "    # Load the tokenizer for the fine-tuned model\n",
    "    models[model]['tokenizer_loaded'] = AutoTokenizer.from_pretrained(models[model]['ft_saving_dir'])\n",
    "\n",
    "    # Load the model\n",
    "    models[model]['ft_model_loaded'] = AutoModelForSequenceClassification.from_pretrained(models[model]['ft_saving_dir'],\n",
    "                                                                                    num_labels=2)\n",
    "    # Define the trainer\n",
    "    models[model]['ft_trainer_loaded'] = Trainer(\n",
    "        model=models[model]['ft_model_loaded'],\n",
    "        tokenizer=models[model]['tokenizer_loaded'],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )"
   ],
   "id": "86df551b6aa2cdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluate the model",
   "id": "d52db478729f7691"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict the test set\n",
    "for model in model_names:\n",
    "    print(f\"Predicting {model}...\")\n",
    "    models[model]['ft_predictions'] = models[model]['ft_trainer_loaded'].predict(models[model]['ft_dataset']['test'])"
   ],
   "id": "e8e6d4fa7dd17399",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the predictions\n",
    "models[model_names[0]]['ft_predictions']"
   ],
   "id": "2beee24282f504bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compute relevant metrics",
   "id": "7ca2c4b7f95de2dd"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a dictionary to store the results\n",
    "results_ft = {}\n",
    "\n",
    "# Iterate over the model names\n",
    "for model in model_names:\n",
    "    # Get the predicted labels\n",
    "    predicted_labels = np.argmax(models[model]['ft_predictions'].predictions, axis=-1)\n",
    "\n",
    "    # Get the true labels\n",
    "    true_labels = models[model]['ft_predictions'].label_ids\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    confusion = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the precision\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the recall\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    results_ft[model] = {\n",
    "        'confusion_matrix': confusion,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }"
   ],
   "id": "6c7554a9349bf7a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the results to a dataframe\n",
    "results_transformers = []\n",
    "for model, metrics in results_ft.items():\n",
    "    results_transformers.append({\n",
    "        'Model': model,\n",
    "        'Feature Representation': 'N/A',\n",
    "        'Columns': 'text',\n",
    "        'F1-score': metrics['f1_score'],\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "    })\n",
    "\n",
    "# Create a dataframe from the results\n",
    "results_transformers_ft = pd.DataFrame(results_transformers)\n",
    "\n",
    "results_transformers_ft.sort_values(by='F1-score', ascending=False)"
   ],
   "id": "2ac6a7929c582eff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot the confusion matrix for the best model",
   "id": "6bf2c6d35cee04f6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the labels\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "# Get the name of the model with the highest F1-score in results_transformers_ft\n",
    "best_model = results_transformers_ft.loc[results_transformers_ft['F1-score'].idxmax()]['Model']\n",
    "\n",
    "# Get the confusion matrix for the best model\n",
    "confusion_matrix = results_ft[best_model]['confusion_matrix']\n",
    "\n",
    "# Create the confusion matrix plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "1bd4b822af320999",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load results from previous assignment",
   "id": "eee507257c19662c"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the results from the previous assignment to a list of dictionaries\n",
    "previous_results = pd.read_csv('results/assignment1_comparison.csv')\n",
    "\n",
    "# Display the previous results\n",
    "previous_results"
   ],
   "id": "93f13e42bad5899e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate the results\n",
    "results = pd.concat([previous_results.copy(), results_transformers_ft], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('results/assignment2_comparison.csv', index=False)\n",
    "\n",
    "# Sort the results by f1-score\n",
    "results = results.sort_values(by='F1-score', ascending=False)\n",
    "\n",
    "results"
   ],
   "id": "f4a79acf98eb6802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tuning after domain adaptation",
   "id": "f746098fa4db8444"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization of the dataset",
   "id": "b3bce27a340e330f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tokenization function for domain adaptation dataset\n",
    "def da_tokenize_function(model, examples):  \n",
    "    return model['da_ft_tokenizer'](examples[\"full_text\"], truncation=True, padding='max_length')\n",
    "\n",
    "for model in model_names:\n",
    "    # Define the saving directory of the domain adaptation model\n",
    "    models[model]['da_saving_dir'] = huggingface_owner + \"DA-\" + model.replace(\"/\", \"-\")\n",
    "    \n",
    "    # Load the tokenizer\n",
    "    models[model]['da_ft_tokenizer'] = AutoTokenizer.from_pretrained(models[model]['da_saving_dir'])\n",
    "    \n",
    "    # Create a dataset dictionary for fine-tuning after domain adaptation\n",
    "    models[model]['da_ft_dataset'] = DatasetDict({\n",
    "        'train': train_test['train'],\n",
    "        'validation': valid_test['train'],\n",
    "        'test': valid_test['test']\n",
    "    })\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    models[model]['da_ft_dataset'] = models[model]['da_ft_dataset'].map(\n",
    "        lambda examples: da_tokenize_function(models[model], examples),\n",
    "        batched=True\n",
    "    )"
   ],
   "id": "fe5cccb19a0932a6",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading models for fine-tuning after domain adaptation",
   "id": "2cbdc18b1b917830"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_names:\n",
    "    # Define the saving directory\n",
    "    models[model]['da_ft_saving_dir'] = huggingface_owner + \"DA-FT-\" + model.replace(\"/\", \"-\")\n",
    "\n",
    "    # Load the model\n",
    "    models[model]['da_ft_model'] = AutoModelForSequenceClassification.from_pretrained(models[model]['da_saving_dir'],\n",
    "                                                                                      num_labels=2)\n",
    "\n",
    "    # Define the training arguments\n",
    "    models[model]['da_ft_training_args'] = TrainingArguments(\n",
    "        output_dir=\"./da_ft_training_results/\" + model.replace(\"/\", \"-\"),\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        push_to_hub=True,\n",
    "        hub_model_id=models[model]['da_ft_saving_dir'],\n",
    "    )\n",
    "\n",
    "    # Define the data collator\n",
    "    models[model]['da_ft_data_collator'] = DataCollatorWithPadding(tokenizer=models[model]['da_ft_tokenizer'])\n",
    "\n",
    "    # Define the trainer\n",
    "    models[model]['da_ft_trainer'] = Trainer(\n",
    "        model=models[model]['da_ft_model'],\n",
    "        args=models[model]['da_ft_training_args'],\n",
    "        train_dataset=models[model]['da_ft_dataset']['train'],\n",
    "        eval_dataset=models[model]['da_ft_dataset']['validation'],\n",
    "        data_collator=models[model]['da_ft_data_collator'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=models[model]['da_ft_tokenizer']\n",
    "    )\n",
    "\n"
   ],
   "id": "94424e71bfe5ffb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fine-tuning the models after domain adaptation",
   "id": "438bccbef75f801e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "da_ft_train = True\n",
    "if da_ft_train:\n",
    "    # Train the models\n",
    "    for model in model_names:\n",
    "        print(f\"Training {model}...\")\n",
    "        models[model]['da_ft_trainer'].train()"
   ],
   "id": "80b9ecd40f0340b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluating the models after fine-tuning",
   "id": "752b22155036db51"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if da_ft_train:\n",
    "    # Evaluate the models\n",
    "    for model in model_names:\n",
    "        print(f\"Evaluating {model}...\")\n",
    "        models[model]['da_ft_trainer'].evaluate()"
   ],
   "id": "d75253384b54399d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving the models to the hub after fine-tuning",
   "id": "4253bbcec5c1bc6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "if da_ft_train:\n",
    "    # Save the models to the hub\n",
    "    for model in model_names:\n",
    "        print(f\"Pushing {model} to Hugging Face...\")\n",
    "        models[model]['da_ft_trainer'].push_to_hub()"
   ],
   "id": "8273e7a6e17d8840",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading trained models after fine-tuning",
   "id": "2b623c76e00a48e6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_names:\n",
    "    # Load the tokenizer\n",
    "    models[model]['da_ft_tokenizer_loaded'] = AutoTokenizer.from_pretrained(models[model]['da_ft_saving_dir'])\n",
    "\n",
    "    # Load the model\n",
    "    models[model]['da_ft_model_loaded'] = AutoModelForSequenceClassification.from_pretrained(\n",
    "        models[model]['da_ft_saving_dir'], num_labels=2)\n",
    "    # Define the trainer\n",
    "    models[model]['da_ft_trainer_loaded'] = Trainer(\n",
    "        model=models[model]['da_ft_model_loaded'],\n",
    "        tokenizer=models[model]['da_ft_tokenizer_loaded'],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )"
   ],
   "id": "1a8b2cc15219b647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Predicting the test set",
   "id": "63974c4d0de8b153"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "for model in model_names:\n",
    "    # Predict the test set\n",
    "    print(f\"Predicting {model}...\")\n",
    "    models[model]['da_predictions'] = models[model]['da_ft_trainer_loaded'].predict(models[model]['da_ft_dataset']['test'])"
   ],
   "id": "962038257249011a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "be303a86ac1ff705"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Display the predictions\n",
    "models[model_names[0]]['da_predictions']"
   ],
   "id": "4e231c28c950be05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compute relevant metrics\n",
   "id": "c07a6dc009462c6d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a dictionary to store the results\n",
    "results_da = {}\n",
    "\n",
    "# Iterate over the model names\n",
    "for model in model_names:\n",
    "    # Get the predicted labels\n",
    "    predicted_labels = np.argmax(models[model]['da_predictions'].predictions, axis=-1)\n",
    "\n",
    "    # Get the true labels\n",
    "    true_labels = models[model]['da_predictions'].label_ids\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    confusion = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the precision\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the recall\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    results_da[model] = {\n",
    "        'confusion_matrix': confusion,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }"
   ],
   "id": "9a25a8512e1264a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save the results to a dataframe",
   "id": "dd9de6f31ea6a07d"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "results_transformers_da = []\n",
    "for model, metrics in results_da.items():\n",
    "    results_transformers_da.append({\n",
    "        'Model': \"DA-\" + model,\n",
    "        'Feature Representation': 'N/A',\n",
    "        'Columns': 'text',\n",
    "        'F1-score': metrics['f1_score'],\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "    })\n",
    "\n",
    "# Create a dataframe from the results\n",
    "results_da = pd.DataFrame(results_transformers_da)\n",
    "\n",
    "results_da"
   ],
   "id": "4c6cb16a312063b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compare with previous results",
   "id": "e8bbf278e35aeed"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Concatenate the results\n",
    "results = pd.concat([results, results_da], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results.to_csv('results/assignment2_comparison_da.csv', index=False)\n",
    "\n",
    "# Sort the results by f1-score\n",
    "results = results.sort_values(by='F1-score', ascending=False)\n",
    "\n",
    "results"
   ],
   "id": "9da7a223aacef436",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "22484212c85999a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
